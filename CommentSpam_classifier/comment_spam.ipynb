{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bagidata_test2",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0KDmpqEgTSe",
        "colab_type": "text"
      },
      "source": [
        "# TASK 2\n",
        "## SPAM COMMENT CLASSIFICATION\n",
        "In every task, I will show the step how to get the model and I will show the prediction step after that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vciTimbChub3",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VMXNSXmqXT0",
        "colab_type": "code",
        "outputId": "16fed425-4d49-45a1-d550-05457f703ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.tokenize.casual import TweetTokenizer\n",
        "import string\n",
        "import re\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,Flatten, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "d = {}"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrV1H22cjk8Q",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Import File for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivAfw5B2rTzv",
        "colab_type": "code",
        "outputId": "1d65fa9e-cf50-4578-c606-625f88e63be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data=pd.read_csv('Comment Spam.csv', encoding='ISO-8859-1', sep=';')\n",
        "print(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        No                                            Comment  Class\n",
            "0        1                                this song is racist      0\n",
            "1        2  and how many subscribers compared to her over ...      1\n",
            "2        3  HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT...      1\n",
            "3        4                                  well done shakira      0\n",
            "4        5                 :D subscribe to me for daily vines      1\n",
            "5        6  Part 2. Holy Mary, pray for us Holy Mother of ...      1\n",
            "6        7   I really can&#39;t comprehend Miley Cyrus , s...      1\n",
            "7        8                                      Nice song ^_^      0\n",
            "8        9                   This makes me miss the world cup      0\n",
            "9       10  ******* Facebook is LAME and so 2004! Check ou...      1\n",
            "10      11  I hope everyone is in good spirits I&#39;m a h...      1\n",
            "11      12                                                 :)      0\n",
            "12      13                                        She is good      0\n",
            "13      14  Subscribe to my Youtube Channel!! :) Suscribit...      1\n",
            "14      15                                          beautiful      0\n",
            "15      16  Earn money for being online with 0 efforts!   ...      1\n",
            "16      17  **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...      1\n",
            "17      18  Hello everyone, It Is not my intention to spam...      1\n",
            "18      19  ******* Facebook is LAME and so 2004! Check ou...      1\n",
            "19      20  Could you please check out my covers on my cha...      1\n",
            "20      21  Hello everyone :) I know most of you probably ...      1\n",
            "21      22                               her voice is so wow!      0\n",
            "22      23  Hi there, have you heard about DribbleProShot?...      1\n",
            "23      24  Meet The Richest Online Marketer  NOW CLICK : ...      1\n",
            "24      25                                        Shakira :-*      0\n",
            "25      26                                                wow      0\n",
            "26      27                                          the best!      0\n",
            "27      28                         SUBSCRIBE ME AND I REQUITE      1\n",
            "28      29  You guys should check out this EXTRAORDINARY w...      1\n",
            "29      30                                 Shakira is perfect      0\n",
            "...    ...                                                ...    ...\n",
            "1270  1271  This Will Always Be My Favorite Song<br />But ...      0\n",
            "1271  1272  Come and watch my video it is called the odowd...      1\n",
            "1272  1273  Check out this video on YouTube: <a href=\"http...      1\n",
            "1273  1274  Love this song! My soccer team made a cd for o...      0\n",
            "1274  1275                                     super rihanna?      0\n",
            "1275  1276                   5th most viewed video.. i guess?      0\n",
            "1276  1277                                              Like?      0\n",
            "1277  1278                  Check out this video on YouTube:?      1\n",
            "1278  1279                                       tension?????      0\n",
            "1279  1280            watch?v=vtaRGgvGtWQ   Check this out .?      1\n",
            "1280  1281  Watch Maroon 5's latest 2nd single from V (It ...      1\n",
            "1281  1282  How is this the most watched Eminem video, it ...      0\n",
            "1282  1283  i love you katy perry because you will sing ni...      0\n",
            "1283  1284                  Check out this video on YouTube:?      1\n",
            "1284  1285                                  PARTY ROCK (8) ~?      0\n",
            "1285  1286  Gusttavo Lima Você não me conhece <br />Check ...      1\n",
            "1286  1287                cool song ever good thing its here?      0\n",
            "1287  1288                                  I lover this song      0\n",
            "1288  1289  Check out this video on YouTube<br /><br /><br...      1\n",
            "1289  1290                  Check out this video on YouTube:?      1\n",
            "1290  1291                            I love the way you lie?      0\n",
            "1291  1292                                   Love the video ?      0\n",
            "1292  1293  shuffle!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...      0\n",
            "1293  1294  https://www.facebook.com/pages/Brew-Crew-2014/...      1\n",
            "1294  1295  Party rock anthem is love,party rock anthem is...      0\n",
            "1295  1296                                      Awsome<br />?      0\n",
            "1296  1297                https://www.tsu.co/KodysMan plz ^^?      1\n",
            "1297  1298  Sign up for free on TSU and start making money...      1\n",
            "1298  1299  MEGAN FOX AND EMINEM TOGETHER IN A VIDEO  DOES...      0\n",
            "1299  1300                              Great.This is a song?      0\n",
            "\n",
            "[1300 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt8CqU_GsTzV",
        "colab_type": "code",
        "outputId": "5788bcee-e40d-4ce4-e2c5-e5dcb22b3dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_komen=data['Comment']\n",
        "print(data_komen)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                     this song is racist\n",
            "1       and how many subscribers compared to her over ...\n",
            "2       HI! CHECK OUT OUR AWESOME COVERS! AND SAY WHAT...\n",
            "3                                       well done shakira\n",
            "4                      :D subscribe to me for daily vines\n",
            "5       Part 2. Holy Mary, pray for us Holy Mother of ...\n",
            "6        I really can&#39;t comprehend Miley Cyrus , s...\n",
            "7                                           Nice song ^_^\n",
            "8                        This makes me miss the world cup\n",
            "9       ******* Facebook is LAME and so 2004! Check ou...\n",
            "10      I hope everyone is in good spirits I&#39;m a h...\n",
            "11                                                     :)\n",
            "12                                            She is good\n",
            "13      Subscribe to my Youtube Channel!! :) Suscribit...\n",
            "14                                              beautiful\n",
            "15      Earn money for being online with 0 efforts!   ...\n",
            "16      **CHECK OUT MY NEW MIXTAPE**** **CHECK OUT MY ...\n",
            "17      Hello everyone, It Is not my intention to spam...\n",
            "18      ******* Facebook is LAME and so 2004! Check ou...\n",
            "19      Could you please check out my covers on my cha...\n",
            "20      Hello everyone :) I know most of you probably ...\n",
            "21                                   her voice is so wow!\n",
            "22      Hi there, have you heard about DribbleProShot?...\n",
            "23      Meet The Richest Online Marketer  NOW CLICK : ...\n",
            "24                                            Shakira :-*\n",
            "25                                                    wow\n",
            "26                                              the best!\n",
            "27                             SUBSCRIBE ME AND I REQUITE\n",
            "28      You guys should check out this EXTRAORDINARY w...\n",
            "29                                     Shakira is perfect\n",
            "                              ...                        \n",
            "1270    This Will Always Be My Favorite Song<br />But ...\n",
            "1271    Come and watch my video it is called the odowd...\n",
            "1272    Check out this video on YouTube: <a href=\"http...\n",
            "1273    Love this song! My soccer team made a cd for o...\n",
            "1274                                       super rihanna?\n",
            "1275                     5th most viewed video.. i guess?\n",
            "1276                                                Like?\n",
            "1277                    Check out this video on YouTube:?\n",
            "1278                                         tension?????\n",
            "1279              watch?v=vtaRGgvGtWQ   Check this out .?\n",
            "1280    Watch Maroon 5's latest 2nd single from V (It ...\n",
            "1281    How is this the most watched Eminem video, it ...\n",
            "1282    i love you katy perry because you will sing ni...\n",
            "1283                    Check out this video on YouTube:?\n",
            "1284                                    PARTY ROCK (8) ~?\n",
            "1285    Gusttavo Lima Você não me conhece <br />Check ...\n",
            "1286                  cool song ever good thing its here?\n",
            "1287                                    I lover this song\n",
            "1288    Check out this video on YouTube<br /><br /><br...\n",
            "1289                    Check out this video on YouTube:?\n",
            "1290                              I love the way you lie?\n",
            "1291                                     Love the video ?\n",
            "1292    shuffle!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...\n",
            "1293    https://www.facebook.com/pages/Brew-Crew-2014/...\n",
            "1294    Party rock anthem is love,party rock anthem is...\n",
            "1295                                        Awsome<br />?\n",
            "1296                  https://www.tsu.co/KodysMan plz ^^?\n",
            "1297    Sign up for free on TSU and start making money...\n",
            "1298    MEGAN FOX AND EMINEM TOGETHER IN A VIDEO  DOES...\n",
            "1299                                Great.This is a song?\n",
            "Name: Comment, Length: 1300, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyJBbH3jzAY",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8PDW05hmQ2u",
        "colab_type": "code",
        "outputId": "d18d8fdc-47b5-4a2d-9210-7aaf7bc0fe26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "komen_bersih1=[]\n",
        "link=r'https?://[A-Za-z0-9./-]+'\n",
        "for komen in data_komen:\n",
        "  komen=re.sub(link, \"\",komen)\n",
        "  komen=re.sub(\"[0-9]\", \"\", komen)\n",
        "  komen_bersih1.append(komen)\n",
        "print(komen_bersih1[1293])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Like this  facebook-page! Chance to win an Iphone S!?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UP229EyrsXH",
        "colab_type": "code",
        "outputId": "b50bb553-0aa1-4cdb-817d-36104f0f0c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "komen_word_tokenize=[]\n",
        "for komen in komen_bersih1:\n",
        "  komen=TweetTokenizer().tokenize(komen)\n",
        "  komen_word_tokenize.append(komen)\n",
        "print(komen_word_tokenize[1293])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Like', 'this', 'facebook-page', '!', 'Chance', 'to', 'win', 'an', 'Iphone', 'S', '!', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yznfpgFWkk0u",
        "colab_type": "code",
        "outputId": "07931497-5469-4200-f48f-9a53a7db95df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open ('dictionary.txt') as text:\n",
        "    for line in text:\n",
        "        if line.strip():\n",
        "            key, val = line.split(None, 1)\n",
        "            d[key]=val.split()\n",
        "\n",
        "def mencaritypo(kata):\n",
        "    for key in d:\n",
        "        list1=d.get(key)\n",
        "        if kata in list1:\n",
        "            return key\n",
        "    return kata\n",
        "  \n",
        "def replacetypo(tupel):\n",
        "    temp_data=[]\n",
        "    for kalimat in tupel:\n",
        "        temp_kalimat=[]\n",
        "        for kata in kalimat:\n",
        "            lit=kata.replace(kata, mencaritypo(kata))\n",
        "            temp_kalimat.append(lit)\n",
        "        temp_data.append(temp_kalimat)      \n",
        "    return temp_data\n",
        "\n",
        "komen_emot = replacetypo(komen_word_tokenize)\n",
        "print(komen_emot[11])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['smile']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJM1ToDy8c75",
        "colab_type": "code",
        "outputId": "1e493b39-0660-4d1b-e89c-60dd6fb4d855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "komen_only=[]\n",
        "listtandabaca=set(['.',',','?','/',':',';','{','}','[',']','|','=','+','<','>','_','-','(',')','*','&','^','%','#','@','!'])\n",
        "for komen in komen_emot:\n",
        "  temp=[]\n",
        "  for item in komen:\n",
        "    if item not in listtandabaca:\n",
        "      temp.append(item.lower())\n",
        "  komen_only.append(temp)\n",
        "print(komen_only[1293])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['like', 'this', 'facebook-page', 'chance', 'to', 'win', 'an', 'iphone', 's']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuTmQD40vY08",
        "colab_type": "code",
        "outputId": "2fe2fb55-c74e-4b01-f1ba-61089415c64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "pip install glove_python"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.16.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.3.1)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=700253 sha256=567ef12371b89cc157a05071ad4287febe89ab95976263ef698c4462478bdac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej6Ax-amkEiZ",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5pAxZXtvZXi",
        "colab_type": "code",
        "outputId": "9672379c-cd3f-4c3e-e3e5-7dff40930ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "#importing the glove library\n",
        "from glove import Corpus, Glove\n",
        "# creating a corpus object\n",
        "corpus = Corpus() \n",
        "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(komen_only, window=5)\n",
        "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "#We can set the learning rate as it uses Gradient Descent and number of components\n",
        "glove = Glove(no_components=5, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove2.model')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxTi5GVvmpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove.add_dictionary(corpus.dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilrhM55Wv0NT",
        "colab_type": "code",
        "outputId": "2396ba56-27df-4df4-d43b-3ee051ac54f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (glove.word_vectors[glove.dictionary['beautiful']])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.06768863  0.02605319 -0.1732963  -0.16988228  0.01360013]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reIBFEWGv2Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "max_len=max(len(kata) for kata in komen_only)\n",
        "\n",
        "def vectorize(dataset, maxlen):\n",
        "  vectorized_komen=[]\n",
        "  expected=[]\n",
        "  for kalimat in dataset:\n",
        "    sample_vecs=[]\n",
        "    for kata in kalimat:\n",
        "      try:\n",
        "        sample_vecs.append(glove.word_vectors[glove.dictionary[kata]])\n",
        "      except:\n",
        "        sample_vecs.append(np.random.uniform(0.0,0.0,5))\n",
        "    if len(sample_vecs)<maxlen:\n",
        "      add=maxlen-len(sample_vecs)\n",
        "      for _ in range(add):\n",
        "        sample_vecs.append(np.random.uniform(0.0,0.0,5))\n",
        "    sample_vecs=np.array(sample_vecs)\n",
        "    vectorized_komen.append(sample_vecs)\n",
        "  vectorized_komen=np.array(vectorized_komen)\n",
        "  return vectorized_komen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOzjvc4wgIeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3261afa9-93da-4121-8c7b-42d6f4df40f2"
      },
      "source": [
        "max_len"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKJm-VY8wH5W",
        "colab_type": "code",
        "outputId": "6592276a-b416-43f0-a008-dcd1382f31c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "vektor_komen=vectorize(komen_only,max_len)\n",
        "vektor_komen[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.90503159,  0.41961604,  1.23528979, -0.21269456,  1.07244588],\n",
              "       [-0.51759033,  0.8241379 ,  0.67556987, -0.52630759,  0.52874512],\n",
              "       [-0.71927016,  0.636317  ,  0.55377084, -0.4538883 ,  0.53426924],\n",
              "       ...,\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF0V1uT_kJw2",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhHx3cGCwlqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting data\n",
        "split_point=int(len(data)*.8)\n",
        "x_train = vektor_komen[:split_point]\n",
        "y_train = data['Class'][:split_point]\n",
        "x_test = vektor_komen[split_point:]\n",
        "y_test = data['Class'][split_point:]\n",
        "\n",
        "Y_train=pd.get_dummies(y_train).values\n",
        "Y_test=pd.get_dummies(y_test).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_ZLqCPRkO7T",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkrIMTDww2Ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Membangun model\n",
        "model = Sequential()\n",
        "embedding_dims=5\n",
        "hidden_dims=10\n",
        "model.add(Conv1D(filters=10,\n",
        "                  strides=1,\n",
        "                  kernel_size=5,\n",
        "                  padding='valid',\n",
        "                  activation='relu',\n",
        "                  input_shape=(max_len, embedding_dims)))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Conv1D(filters=5,\n",
        "                 strides=1,\n",
        "                  kernel_size=5,\n",
        "                  padding='valid',\n",
        "                  activation='relu'))\n",
        "model.add(MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(int(hidden_dims), activation='sigmoid'))\n",
        "model.add(Dense(int(hidden_dims/2), activation='sigmoid'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGjvg1mbw7H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pat = 30 #this is the number of epochs with no improvment after which the training will stop\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=pat, verbose=1, mode='max')\n",
        "\n",
        "#define the model checkpoint callback -> this will keep on saving the model as a physical file\n",
        "model_checkpoint = ModelCheckpoint('best_model2',monitor='val_acc', verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwGkz5NvkayY",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: Training and Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpW4WJdbxFx7",
        "colab_type": "code",
        "outputId": "48f5dbf8-ab52-47f5-ca5e-4a12b96a8139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hasil=model.fit(x_train, Y_train,\n",
        "         batch_size=5,\n",
        "         epochs=500,\n",
        "         verbose=2,\n",
        "         callbacks=[early_stopping, model_checkpoint],\n",
        "         validation_data=(x_test, Y_test))\n",
        "hasil"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1040 samples, validate on 260 samples\n",
            "Epoch 1/500\n",
            " - 2s - loss: 0.7041 - acc: 0.5423 - val_loss: 0.7364 - val_acc: 0.4192\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.41923, saving model to best_model2\n",
            "Epoch 2/500\n",
            " - 0s - loss: 0.6746 - acc: 0.5462 - val_loss: 0.6823 - val_acc: 0.4192\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.41923\n",
            "Epoch 3/500\n",
            " - 0s - loss: 0.6208 - acc: 0.6250 - val_loss: 0.6177 - val_acc: 0.7808\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.41923 to 0.78077, saving model to best_model2\n",
            "Epoch 4/500\n",
            " - 0s - loss: 0.5529 - acc: 0.8173 - val_loss: 0.5563 - val_acc: 0.8308\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78077 to 0.83077, saving model to best_model2\n",
            "Epoch 5/500\n",
            " - 0s - loss: 0.5051 - acc: 0.8462 - val_loss: 0.5055 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.83077 to 0.84231, saving model to best_model2\n",
            "Epoch 6/500\n",
            " - 0s - loss: 0.4563 - acc: 0.8548 - val_loss: 0.4731 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.84231 to 0.84615, saving model to best_model2\n",
            "Epoch 7/500\n",
            " - 0s - loss: 0.4304 - acc: 0.8452 - val_loss: 0.4480 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.84615\n",
            "Epoch 8/500\n",
            " - 0s - loss: 0.4052 - acc: 0.8625 - val_loss: 0.4319 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.84615\n",
            "Epoch 9/500\n",
            " - 0s - loss: 0.3948 - acc: 0.8538 - val_loss: 0.4317 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.84615\n",
            "Epoch 10/500\n",
            " - 0s - loss: 0.3815 - acc: 0.8635 - val_loss: 0.4110 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.84615 to 0.85000, saving model to best_model2\n",
            "Epoch 11/500\n",
            " - 0s - loss: 0.3653 - acc: 0.8596 - val_loss: 0.4013 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.85000\n",
            "Epoch 12/500\n",
            " - 0s - loss: 0.3599 - acc: 0.8663 - val_loss: 0.3919 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.85000 to 0.85000, saving model to best_model2\n",
            "Epoch 13/500\n",
            " - 0s - loss: 0.3459 - acc: 0.8644 - val_loss: 0.3961 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.85000\n",
            "Epoch 14/500\n",
            " - 0s - loss: 0.3446 - acc: 0.8683 - val_loss: 0.3973 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.85000\n",
            "Epoch 15/500\n",
            " - 0s - loss: 0.3445 - acc: 0.8654 - val_loss: 0.3885 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.85000\n",
            "Epoch 16/500\n",
            " - 0s - loss: 0.3364 - acc: 0.8683 - val_loss: 0.3881 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.85000\n",
            "Epoch 17/500\n",
            " - 0s - loss: 0.3419 - acc: 0.8731 - val_loss: 0.3864 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.85000\n",
            "Epoch 18/500\n",
            " - 0s - loss: 0.3297 - acc: 0.8692 - val_loss: 0.3858 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.85000\n",
            "Epoch 19/500\n",
            " - 0s - loss: 0.3239 - acc: 0.8712 - val_loss: 0.3890 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.85000\n",
            "Epoch 20/500\n",
            " - 0s - loss: 0.3139 - acc: 0.8692 - val_loss: 0.3904 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.85000 to 0.85385, saving model to best_model2\n",
            "Epoch 21/500\n",
            " - 1s - loss: 0.3241 - acc: 0.8702 - val_loss: 0.3868 - val_acc: 0.8538\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.85385\n",
            "Epoch 22/500\n",
            " - 0s - loss: 0.3168 - acc: 0.8769 - val_loss: 0.3892 - val_acc: 0.8654\n",
            "\n",
            "Epoch 00022: val_acc improved from 0.85385 to 0.86538, saving model to best_model2\n",
            "Epoch 23/500\n",
            " - 0s - loss: 0.3120 - acc: 0.8779 - val_loss: 0.3877 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.86538\n",
            "Epoch 24/500\n",
            " - 1s - loss: 0.3042 - acc: 0.8817 - val_loss: 0.3913 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.86538\n",
            "Epoch 25/500\n",
            " - 0s - loss: 0.3091 - acc: 0.8808 - val_loss: 0.3898 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.86538\n",
            "Epoch 26/500\n",
            " - 0s - loss: 0.3054 - acc: 0.8875 - val_loss: 0.4013 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.86538\n",
            "Epoch 27/500\n",
            " - 0s - loss: 0.2974 - acc: 0.8885 - val_loss: 0.4265 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.86538\n",
            "Epoch 28/500\n",
            " - 0s - loss: 0.3085 - acc: 0.8760 - val_loss: 0.4019 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.86538\n",
            "Epoch 29/500\n",
            " - 0s - loss: 0.2986 - acc: 0.8827 - val_loss: 0.3970 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.86538\n",
            "Epoch 30/500\n",
            " - 0s - loss: 0.2892 - acc: 0.8904 - val_loss: 0.3940 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.86538\n",
            "Epoch 31/500\n",
            " - 0s - loss: 0.2913 - acc: 0.8865 - val_loss: 0.3992 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.86538\n",
            "Epoch 32/500\n",
            " - 0s - loss: 0.2828 - acc: 0.8933 - val_loss: 0.4008 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.86538\n",
            "Epoch 33/500\n",
            " - 0s - loss: 0.2741 - acc: 0.8962 - val_loss: 0.4054 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.86538\n",
            "Epoch 34/500\n",
            " - 0s - loss: 0.2823 - acc: 0.8952 - val_loss: 0.4263 - val_acc: 0.8231\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.86538\n",
            "Epoch 35/500\n",
            " - 0s - loss: 0.2782 - acc: 0.8933 - val_loss: 0.4055 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.86538\n",
            "Epoch 36/500\n",
            " - 0s - loss: 0.2788 - acc: 0.9000 - val_loss: 0.4046 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.86538\n",
            "Epoch 37/500\n",
            " - 0s - loss: 0.2693 - acc: 0.9000 - val_loss: 0.4129 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.86538\n",
            "Epoch 38/500\n",
            " - 0s - loss: 0.2831 - acc: 0.8952 - val_loss: 0.4083 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.86538\n",
            "Epoch 39/500\n",
            " - 0s - loss: 0.2634 - acc: 0.9067 - val_loss: 0.4150 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.86538\n",
            "Epoch 40/500\n",
            " - 0s - loss: 0.2619 - acc: 0.9029 - val_loss: 0.4121 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.86538\n",
            "Epoch 41/500\n",
            " - 0s - loss: 0.2656 - acc: 0.9038 - val_loss: 0.4107 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.86538\n",
            "Epoch 42/500\n",
            " - 1s - loss: 0.2665 - acc: 0.9067 - val_loss: 0.4166 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.86538\n",
            "Epoch 43/500\n",
            " - 0s - loss: 0.2648 - acc: 0.9010 - val_loss: 0.4267 - val_acc: 0.8269\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.86538\n",
            "Epoch 44/500\n",
            " - 0s - loss: 0.2502 - acc: 0.9096 - val_loss: 0.4139 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.86538\n",
            "Epoch 45/500\n",
            " - 0s - loss: 0.2431 - acc: 0.9096 - val_loss: 0.4225 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.86538\n",
            "Epoch 46/500\n",
            " - 0s - loss: 0.2610 - acc: 0.9019 - val_loss: 0.4310 - val_acc: 0.8385\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.86538\n",
            "Epoch 47/500\n",
            " - 0s - loss: 0.2570 - acc: 0.9029 - val_loss: 0.4220 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.86538\n",
            "Epoch 48/500\n",
            " - 0s - loss: 0.2465 - acc: 0.9077 - val_loss: 0.4269 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.86538\n",
            "Epoch 49/500\n",
            " - 0s - loss: 0.2525 - acc: 0.9058 - val_loss: 0.4440 - val_acc: 0.8346\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.86538\n",
            "Epoch 50/500\n",
            " - 0s - loss: 0.2469 - acc: 0.9048 - val_loss: 0.4456 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.86538\n",
            "Epoch 51/500\n",
            " - 0s - loss: 0.2430 - acc: 0.9096 - val_loss: 0.4350 - val_acc: 0.8423\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.86538\n",
            "Epoch 52/500\n",
            " - 0s - loss: 0.2297 - acc: 0.9154 - val_loss: 0.4381 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.86538\n",
            "Epoch 00052: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed4bba1160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9w2qEOVxLF_",
        "colab_type": "code",
        "outputId": "b716466f-3650-4b25-abc4-c798214716ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(hasil.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkeTG9RoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jemeJCXZkiv_",
        "colab_type": "text"
      },
      "source": [
        "## Classifier\n",
        "In this part, I will make the classifier for user who want to classify their comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8VBL4LtxbVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_comment=('Please input your comment here')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVUl-bjCk0j5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be6360c4-4372-4f8c-8800-bb3c361f9b49"
      },
      "source": [
        "listtandabaca=set(['.',',','?','/',':',';','{','}','[',']','|','=','+','<','>','_','-','(',')','*','&','^','%','#','@','!'])\n",
        "link=r'https?://[A-Za-z0-9./-]+'\n",
        "input_data=re.sub(link,\"\",input_comment)\n",
        "input_data=re.sub('[0-9]',\"\",input_data)\n",
        "input_data=TweetTokenizer().tokenize(input_data)\n",
        "with open ('dictionary.txt') as text:\n",
        "    for line in text:\n",
        "        if line.strip():\n",
        "            key, val = line.split(None, 1)\n",
        "            d[key]=val.split()\n",
        "input_fix=[]\n",
        "input_fix.append(input_data)\n",
        "input_fix=replacetypo(input_fix)\n",
        "input_only=[]\n",
        "for komen in input_fix:\n",
        "  temp=[]\n",
        "  for item in komen:\n",
        "    if item not in listtandabaca:\n",
        "      temp.append(item.lower())\n",
        "  input_only.append(temp)\n",
        "vector_comment=vectorize(input_only,max_len)\n",
        "best_model=load_model('best_model2_86%')\n",
        "output=best_model.predict_classes(vector_comment)\n",
        "output=str(output)\n",
        "if output==('[0]'):\n",
        "  print('This comment is not a spam')\n",
        "elif output==('[1]'):\n",
        "  print('Watchout, THIS IS A SPAM!!!')\n",
        "else:\n",
        "  print('ERROR')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This comment is not a spam\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}